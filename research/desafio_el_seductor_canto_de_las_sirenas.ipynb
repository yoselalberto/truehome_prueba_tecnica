{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# El seductor canto de las sirenas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencias\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   seaborn                 import scatterplot, pairplot\n",
    "from   sklearn.preprocessing   import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.linear_model    import LogisticRegression\n",
    "from   sklearn.svm             import LinearSVC\n",
    "from   sklearn.metrics         import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "path_sirenas_historico    = 'work/datasets/sirenas_endemicas_y_sirenas_migrantes_historico.csv'\n",
    "path_sirenas_nuevas       = 'work/datasets/sirenas_endemicas_y_sirenas_migrantes.csv'\n",
    "# output\n",
    "path_sirenas_predicciones = 'work/datasets/sirenas_endemicas_y_sirenas_migrantes_con_predicciones.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sirenas_historico = pd.read_csv(path_sirenas_historico)\n",
    "sirenas_nuevas    = pd.read_csv(path_sirenas_nuevas)"
   ]
  },
  {
   "source": [
    "## Exploración inicial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeros y últimos registros\n",
    "print(sirenas_historico.head())\n",
    "print(sirenas_historico.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estadística descriptiva\n",
    "sirenas_historico.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sirenas por especie\n",
    "sirenas_historico.groupby(['especie']).agg(['count'])"
   ]
  },
  {
   "source": [
    "La cantidad de sirenas esta perfectamente balanceada."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Separación en train and test\n",
    "Tenemos 100 observaciones, las clases están balanceadas, ambas tienen `50%` de las observaciones; usaré el `80%` de las observaciones para encontrar el mejor modelo predictivo, y el `20%` restante para medir su desempeño esperado en el mundo real."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## llevo los datos a un formato para scikit-learn\n",
    "# definición de las columnas\n",
    "columnas_predictoras = ['v1', 'v2', 'v3', 'v4']\n",
    "columna_objetivo     = ['especie']\n",
    "# separación \n",
    "predictores = sirenas_historico[columnas_predictoras]\n",
    "objetivo    = sirenas_historico[columna_objetivo]\n",
    "# train_test_split\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(predictores, objetivo, random_state = 42, test_size = 0.2, shuffle = True, stratify = objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráficas de dispersión del conjunto de entrenamiento\n",
    "pairplot(pd.concat([x_train, y_train], axis = 1, ignore_index = True), hue = 4)"
   ]
  },
  {
   "source": [
    "##\n",
    "Las gráficas de dispersión sugieren que las dos clases de sirenas, endemicas y migrantes, son linealmente separables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Ingeniería de variables\n",
    "Estandarizaré las variables, luego añadire las interacciones entre las variables; para la variable objetivo mapearé las sirenas endemicas a `0` y las migrantes a `1`, el formato esperado por scikit-learn (y las mayorias de las librerias).\n",
    "\n",
    "Probaré dos versiones de los datos preparados, una con solo las variables estandarizadas, y otra con las interacciones añadidas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarización: después de esta transformación las variables tendrán promedio 0 y desviación estandar 1\n",
    "# ajuste\n",
    "estandarizador = StandardScaler(with_mean = True, with_std = True).fit(x_train)\n",
    "# transformación\n",
    "x_train_estandarizados = estandarizador.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# añado las interacciones\n",
    "# ajuste\n",
    "poly = PolynomialFeatures(interaction_only = True, include_bias = False).fit(x_train_estandarizados)\n",
    "# transformación\n",
    "x_train_con_interacciones = poly.transform(x_train_estandarizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparación del la variable objetivo, espera 0 o 1, transformaré las endemicas a 0  y las migrantes a 1\n",
    "# y_train_encoded = encoder.transform(y_train)\n",
    "codificacion_objetivo = {'especie': {'sirena_endemica': 0, 'sirena_migrante': 1}}\n",
    "y_train_encoded       = y_train.replace(codificacion_objetivo)"
   ]
  },
  {
   "source": [
    "## Modelado\n",
    "Tenemos un problema de clasificación binaria, con ambas clases perfectamente balanceadas (50% de cada una). Probaré una **regresión logística** clásica, y una **máquina de vectores de soporte (support-vector machine)**; además, usaré validación cruzada y exploraré el espacio de los modelos.  \n",
    "\n",
    "Dado qué las clases están balanceadas, usaré el **f1 score**, la media armónica entre precisión y exhaustividad, como métrica para determinar el mejor modelo prédictivo (más es mejor); en algunas circunstancias la precisión o la exhaustividad tendrían más sentido, e.g. una especie es más agresiva hacía la otra, pero dado la información disponible el **f1 score** es una buena opción."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluador para la exploración del espacio de modelos\n",
    "scorer_f1  = make_scorer(f1_score)"
   ]
  },
  {
   "source": [
    "### Regresión logística"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros a explorar\n",
    "parameters_logit = {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'C': [0.1, 0.5, 1, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versión sin interacciones\n",
    "# declaro el modelo\n",
    "modelo_logit_estandarizado = GridSearchCV(LogisticRegression(solver = 'saga', random_state = 42, n_jobs = 1), param_grid = parameters_logit, n_jobs = 6, cv = 4, scoring = scorer_f1)\n",
    "# ajusto el modelo\n",
    "modelo_logit_estandarizado.fit(X = x_train_estandarizados, y = y_train_encoded)\n",
    "# extraigo el mejor modelo\n",
    "modelo_logit_estandarizado_mejor = modelo_logit_estandarizado.best_estimator_\n",
    "# vistazo rápido\n",
    "print(modelo_logit_estandarizado_mejor)\n",
    "print(modelo_logit_estandarizado.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresión logística con interacciones\n",
    "# declaro el modelo\n",
    "modelo_logit_interacciones = GridSearchCV(LogisticRegression(solver = 'saga', random_state = 42, n_jobs = 1), param_grid = parameters_logit, n_jobs = 6, cv = 4, scoring = scorer_f1)\n",
    "# ajusto el modelo\n",
    "modelo_logit_interacciones.fit(X = x_train_con_interacciones, y = y_train_encoded)\n",
    "# extraigo el mejor modelo\n",
    "modelo_logit_interacciones_mejor = modelo_logit_interacciones.best_estimator_\n",
    "# vistazo rápido\n",
    "print(modelo_logit_interacciones_mejor)\n",
    "print(modelo_logit_interacciones.best_score_)"
   ]
  },
  {
   "source": [
    "### Máquina de vectores de soporte (support-vector machine)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros a probar\n",
    "parameters_svm = {'penalty': ['l1', 'l2'], 'C': [0.1, .5, 1, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm sin interacciones\n",
    "# declaro el modelo\n",
    "modelo_svm_estandarizado = GridSearchCV(LinearSVC(random_state = 42), param_grid = parameters_svm, n_jobs = 6, cv = 4, scoring = scorer_f1)\n",
    "# ajusto el modelo\n",
    "modelo_svm_estandarizado.fit(X = x_train_estandarizados, y = y_train_encoded)\n",
    "# extraigo el mejor modelo\n",
    "modelo_svm_estandarizado_mejor = modelo_svm_estandarizado.best_estimator_ \n",
    "# vistazo\n",
    "print(modelo_svm_estandarizado_mejor)\n",
    "print(modelo_svm_estandarizado.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm con interacciones\n",
    "# declaro el modelo\n",
    "modelo_svm_interacciones = GridSearchCV(LinearSVC(random_state = 42), param_grid = parameters_svm, n_jobs = 6, cv = 4, scoring = scorer_f1)\n",
    "# ajusto el modelo\n",
    "modelo_svm_interacciones.fit(X = x_train_con_interacciones, y = y_train_encoded)\n",
    "# extraigo el mejor modelo\n",
    "modelo_svm_interacciones_mejor = modelo_svm_interacciones.best_estimator_ \n",
    "# vistazo\n",
    "print(modelo_svm_interacciones_mejor)\n",
    "print(modelo_svm_interacciones.best_score_)"
   ]
  },
  {
   "source": [
    "## Selección del modelo\n",
    "\n",
    "De las gráficas de dispersión intuí que las dos clases eran linealmente separables, las 4 combinaciones, 2 modelos y 2 entradas diferentes, que probé lograron un desempeño perfecto, `f1 score = 1`; elegiré la aproximación más sencilla: la regressión logística con la entrada sin interacciones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluación del mejor modelo \n",
    "Obtendré el error de generalización, usando el mejor modelo predictivo en los datos de test, y comparando esto con los valores reales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparo la entrada para la predicción\n",
    "# estandarización\n",
    "x_test_estandarizados = estandarizador.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicción\n",
    "prediccion = modelo_logit_estandarizado_mejor.predict(x_test_estandarizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtengo el error de generalización\n",
    "y_test_encoded = y_test.replace(codificacion_objetivo).reset_index(drop = True)\n",
    "#\n",
    "error_generalizacion_f1_score = f1_score(y_test_encoded, prediccion)\n",
    "# print\n",
    "error_generalizacion_f1_score"
   ]
  },
  {
   "source": [
    "Las predicciones son perfectas!!\n",
    "\n",
    "Hay al menos dos opciones, una es que las dos especies de sirenas son linealmente separanles, o que sobreajustamos los modelos; seguí una metodología sólida, así que confiaré en el modelo predictivo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Clasificación de individuos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformo la entrada para la prediccion\n",
    "sirenas_nuevas_estandarizadas = estandarizador.transform(sirenas_nuevas[columnas_predictoras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso el mejor modelo para predecir\n",
    "predicciones_sirenas_nuevas = modelo_logit_estandarizado_mejor.predict(sirenas_nuevas_estandarizadas)\n",
    "# vistazo\n",
    "print(predicciones_sirenas_nuevas)"
   ]
  },
  {
   "source": [
    "## Salida\n",
    "Añadiré las predicciones a la tabla"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copio el dataframe\n",
    "df_salida = sirenas_nuevas.copy()\n",
    "# añado las predicciones\n",
    "df_salida['especie'] = predicciones_sirenas_nuevas\n",
    "# vistazo\n",
    "print(df_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regreso a las etiquetas originales\n",
    "codificacion_objetivo_inversa = {'especie': {0: 'sirena_endemica', 1: 'sirena_migrante'}}\n",
    "# remplazo\n",
    "df_salida_con_etiquetas = df_salida.replace(codificacion_objetivo_inversa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvado como csv\n",
    "df_salida_con_etiquetas.to_csv(path_sirenas_predicciones, index = False)"
   ]
  },
  {
   "source": [
    "## Conclusiones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}